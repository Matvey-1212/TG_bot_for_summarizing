{
    "model_name": "mtvA/rugpt3medium_sum",
    "rouge": {
        "rouge1": 0.2268121011616014,
        "rouge2": 0.11417797601503119,
        "rougeL": 0.21383246105872322,
        "rougeLsum": 0.21965310563779616
    },
    "bertscore": {
        "precision": 0.6823671483254248,
        "recall": 0.7874921266884767,
        "f1": 0.7305448759895886,
        "hashcode": "bert-base-multilingual-cased_L9_no-idf_version=0.3.12(hug_trans=4.47.1)"
    }
}